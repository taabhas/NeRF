{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLDTVWKq7-ei"
      },
      "source": [
        "##Tiny NeRF\n",
        "This is a simplied version of the method presented in *NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis*\n",
        "\n",
        "[Project Website](http://www.matthewtancik.com/nerf)\n",
        "\n",
        "[arXiv Paper](https://arxiv.org/abs/2003.08934)\n",
        "\n",
        "[Full Code](github.com/bmild/nerf)\n",
        "\n",
        "Components not included in the notebook\n",
        "*   5D input including view directions\n",
        "*   Hierarchical Sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bZNXlxmEj0FC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2856c836-feee-49ee-eae7-9257f469b946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    %tensorflow_version 2.x\n",
        "\n",
        "import os, sys\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5mTxAwgrj4yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b751d6a5-bd1c-4232-8b47-473c06095445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-12 22:08:05--  http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz\n",
            "Resolving cseweb.ucsd.edu (cseweb.ucsd.edu)... 132.239.8.30\n",
            "Connecting to cseweb.ucsd.edu (cseweb.ucsd.edu)|132.239.8.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cseweb.ucsd.edu//~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz [following]\n",
            "--2023-03-12 22:08:05--  https://cseweb.ucsd.edu//~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz\n",
            "Connecting to cseweb.ucsd.edu (cseweb.ucsd.edu)|132.239.8.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12727482 (12M)\n",
            "Saving to: ‘tiny_nerf_data.npz’\n",
            "\n",
            "tiny_nerf_data.npz  100%[===================>]  12.14M  7.01MB/s    in 1.7s    \n",
            "\n",
            "2023-03-12 22:08:08 (7.01 MB/s) - ‘tiny_nerf_data.npz’ saved [12727482/12727482]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists('tiny_nerf_data.npz'):\n",
        "    !wget http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2dgdCDi-m3T"
      },
      "source": [
        "# Load Input Images and Poses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jj1lof2ej0FI"
      },
      "outputs": [],
      "source": [
        "data = np.load('tiny_nerf_data.npz')\n",
        "images = data['images']\n",
        "poses = data['poses']\n",
        "focal = data['focal']\n",
        "H, W = images.shape[1:3]\n",
        "\n",
        "\n",
        "testimg, testpose = images[101], poses[101]\n",
        "images = images[:100,...,:3]\n",
        "poses = poses[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxDt192E-v6i"
      },
      "source": [
        "# Optimize NeRF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R1avtwVoAQTu"
      },
      "outputs": [],
      "source": [
        "def posenc(x):\n",
        "  rets = [x]\n",
        "  for i in range(L_embed):\n",
        "    for fn in [tf.sin, tf.cos]:\n",
        "      rets.append(fn(2.**i * x))\n",
        "  return tf.concat(rets, -1)\n",
        "\n",
        "L_embed = 6\n",
        "embed_fn = posenc\n",
        "# L_embed = 0\n",
        "# embed_fn = tf.identity\n",
        "\n",
        "def init_model(D=8, W=256):\n",
        "    relu = tf.keras.layers.ReLU()    \n",
        "    dense = lambda W=W, act=relu : tf.keras.layers.Dense(W, activation=act)\n",
        "\n",
        "    inputs = tf.keras.Input(shape=(3 + 3*2*L_embed)) \n",
        "    outputs = inputs\n",
        "    for i in range(D):\n",
        "        outputs = dense()(outputs)\n",
        "        if i%4==0 and i>0:\n",
        "            outputs = tf.concat([outputs, inputs], -1)\n",
        "    outputs = dense(4, act=None)(outputs)\n",
        "    \n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def get_rays(H, W, focal, c2w):\n",
        "    i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
        "    dirs = tf.stack([(i-W*.5)/focal, -(j-H*.5)/focal, -tf.ones_like(i)], -1)\n",
        "    rays_d = tf.reduce_sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)\n",
        "    rays_o = tf.broadcast_to(c2w[:3,-1], tf.shape(rays_d))\n",
        "    return rays_o, rays_d\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_stratified(rays_o ,rays_d, near=2.0, far=6.0, n_samples=8):\n",
        "\n",
        "  ray_points = torch.linspace(near, far, n_samples, device=rays_o.device)\n",
        "\n",
        "  ##perturbed ray points\n",
        "  temp_rand = torch.rand([n_samples], device=device)\n",
        "  perturbed_ray_points=(near+(far-near)*temp_rand).sort().values\n",
        "\n",
        "\n",
        "  perturbed_ray_points = perturbed_ray_points.expand(list([rays_o.shape[0]]) + [n_samples]) ### duplicates the perturbed points 10000 times\n",
        "  # list(rays_o.shape[:-1]) + [n_samples] gives (10000,8)\n",
        "\n",
        "  ### To get the actual points we use the following. PT=Origin+Direction*RayPoints(between 2 and 6)\n",
        "\n",
        "  points=rays_o[:, None, :] + rays_d[:, None, :] * perturbed_ray_points[:, :, None]\n",
        "\n",
        "  return points,perturbed_ray_points"
      ],
      "metadata": {
        "id": "26HGPIcrVKX7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoder(nn.Module):\n",
        "  r\"\"\"\n",
        "  Sine-cosine positional encoder for input points.\n",
        "  \"\"\"\n",
        "  def __init__(\n",
        "    self,\n",
        "    d_input: int,\n",
        "    n_freqs: int,\n",
        "    log_space: bool = False\n",
        "  ):\n",
        "    super().__init__()\n",
        "    self.d_input = d_input\n",
        "    self.n_freqs = n_freqs\n",
        "    self.log_space = log_space\n",
        "    self.d_output = d_input * (1 + 2 * self.n_freqs)\n",
        "    self.embed_fns = [lambda x: x]\n",
        "\n",
        "    # Define frequencies in either linear or log scale\n",
        "    if self.log_space:\n",
        "      freq_bands = 2.**torch.linspace(0., self.n_freqs - 1, self.n_freqs)\n",
        "    else:\n",
        "      freq_bands = torch.linspace(2.**0., 2.**(self.n_freqs - 1), self.n_freqs)\n",
        "\n",
        "    # Alternate sin and cos\n",
        "    for freq in freq_bands:\n",
        "      self.embed_fns.append(lambda x, freq=freq: torch.sin(x * freq))\n",
        "      self.embed_fns.append(lambda x, freq=freq: torch.cos(x * freq))\n",
        "  \n",
        "  def forward(\n",
        "    self,\n",
        "    x\n",
        "  ) -> torch.Tensor:\n",
        "    r\"\"\"\n",
        "    Apply positional encoding to input.\n",
        "    \"\"\"\n",
        "    return torch.concat([fn(x) for fn in self.embed_fns], dim=-1)"
      ],
      "metadata": {
        "id": "zBxIJZC7r43w"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def render_rays(network_fn, rays_o, rays_d, near, far, N_samples, rand=False):\n",
        "\n",
        "    def batchify(fn, chunk=1024*32):\n",
        "        return lambda inputs : tf.concat([fn(inputs[i:i+chunk]) for i in range(0, inputs.shape[0], chunk)], 0)\n",
        "    \n",
        "    # Compute 3D query points\n",
        "    z_vals = tf.linspace(near, far, N_samples) \n",
        "    if rand:\n",
        "      z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
        "    pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None]\n",
        "    \n",
        "    # Run network\n",
        "    pts_flat = tf.reshape(pts, [-1,3])\n",
        "    pts_flat = embed_fn(pts_flat)\n",
        "    raw = batchify(network_fn)(pts_flat)\n",
        "    raw = tf.reshape(raw, list(pts.shape[:-1]) + [4])\n",
        "    \n",
        "    # Compute opacities and colors\n",
        "    sigma_a = tf.nn.relu(raw[...,3])\n",
        "    rgb = tf.math.sigmoid(raw[...,:3]) \n",
        "    \n",
        "    # Do volume rendering\n",
        "    dists = tf.concat([z_vals[..., 1:] - z_vals[..., :-1], tf.broadcast_to([1e10], z_vals[...,:1].shape)], -1) \n",
        "    alpha = 1.-tf.exp(-sigma_a * dists)  \n",
        "    weights = alpha * tf.math.cumprod(1.-alpha + 1e-10, -1, exclusive=True)\n",
        "    \n",
        "    rgb_map = tf.reduce_sum(weights[...,None] * rgb, -2) \n",
        "    depth_map = tf.reduce_sum(weights * z_vals, -1) \n",
        "    acc_map = tf.reduce_sum(weights, -1)\n",
        "\n",
        "    return rgb_map, depth_map, acc_map"
      ],
      "metadata": {
        "id": "Eg2tlIJxVH-6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TSAyVcKAiyI"
      },
      "source": [
        "Here we optimize the model. We plot a rendered holdout view and its PSNR every 50 iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6XurcHoCj0FQ"
      },
      "outputs": [],
      "source": [
        "model = init_model()\n",
        "optimizer = tf.keras.optimizers.Adam(5e-4)\n",
        "\n",
        "N_samples = 64\n",
        "N_iters = 1000\n",
        "psnrs = []\n",
        "iternums = []\n",
        "i_plot = 25\n",
        "near, far = 2., 6. \n",
        "n_samples = 8\n",
        "\n",
        "import time\n",
        "t = time.time()\n",
        "for i in range(N_iters+1):\n",
        "    \n",
        "    img_i = np.random.randint(images.shape[0])\n",
        "    target = images[img_i]\n",
        "    pose = poses[img_i]\n",
        "    rays_o, rays_d = get_rays(H, W, focal, pose)\n",
        "    # pts, perturbed_ray_points = sample_stratified(rays_o,rays_d, near, far,n_samples)\n",
        "    with tf.GradientTape() as tape:\n",
        "        rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples, rand=True)\n",
        "        loss = tf.reduce_mean(tf.square(rgb - target))\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    if i%i_plot==0:\n",
        "        # print(i, (time.time() - t) / i_plot, 'secs per iter')\n",
        "        t = time.time()\n",
        "        \n",
        "        # Render the holdout view for logging\n",
        "        rays_o, rays_d = get_rays(H, W, focal, testpose)\n",
        "        rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
        "        loss = tf.reduce_mean(tf.square(rgb - testimg))\n",
        "        psnr = -10. * tf.math.log(loss) / tf.math.log(10.)\n",
        "\n",
        "        psnrs.append(psnr.numpy())\n",
        "        iternums.append(i)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZLEFNox_UVK"
      },
      "source": [
        "# Interactive Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L92jHDI7j0FT"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from ipywidgets import interactive, widgets\n",
        "\n",
        "\n",
        "trans_t = lambda t : tf.convert_to_tensor([\n",
        "    [1,0,0,0],\n",
        "    [0,1,0,0],\n",
        "    [0,0,1,t],\n",
        "    [0,0,0,1],\n",
        "], dtype=tf.float32)\n",
        "\n",
        "rot_phi = lambda phi : tf.convert_to_tensor([\n",
        "    [1,0,0,0],\n",
        "    [0,tf.cos(phi),-tf.sin(phi),0],\n",
        "    [0,tf.sin(phi), tf.cos(phi),0],\n",
        "    [0,0,0,1],\n",
        "], dtype=tf.float32)\n",
        "\n",
        "rot_theta = lambda th : tf.convert_to_tensor([\n",
        "    [tf.cos(th),0,-tf.sin(th),0],\n",
        "    [0,1,0,0],\n",
        "    [tf.sin(th),0, tf.cos(th),0],\n",
        "    [0,0,0,1],\n",
        "], dtype=tf.float32)\n",
        "\n",
        "\n",
        "def pose_spherical(theta, phi, radius):\n",
        "    c2w = trans_t(radius)\n",
        "    c2w = rot_phi(phi/180.*np.pi) @ c2w\n",
        "    c2w = rot_theta(theta/180.*np.pi) @ c2w\n",
        "    c2w = np.array([[-1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]]) @ c2w\n",
        "    return c2w\n",
        "\n",
        "\n",
        "def f(**kwargs):\n",
        "    c2w = pose_spherical(**kwargs)\n",
        "    rays_o, rays_d = get_rays(H, W, focal, c2w[:3,:4])\n",
        "    rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
        "    img = np.clip(rgb,0,1)\n",
        "    \n",
        "    plt.figure(2, figsize=(20,6))\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "sldr = lambda v, mi, ma: widgets.FloatSlider(\n",
        "    value=v,\n",
        "    min=mi,\n",
        "    max=ma,\n",
        "    step=.01,\n",
        ")\n",
        "\n",
        "names = [\n",
        "    ['theta', [100., 0., 360]],\n",
        "    ['phi', [-30., -90, 0]],\n",
        "    ['radius', [4., 3., 5.]],\n",
        "]\n",
        "\n",
        "# interactive_plot = interactive(f, **{s[0] : sldr(*s[1]) for s in names})\n",
        "# output = interactive_plot.children[-1]\n",
        "# output.layout.height = '350px'\n",
        "# interactive_plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpKhAn2a__Iu"
      },
      "source": [
        "# Render 360 Video"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio-ffmpeg\n",
        "# import imageio-ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ITLOGjbSioU",
        "outputId": "95380be5-6f32-4a50-9074-6102eeafb6e4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting imageio-ffmpeg\n",
            "  Downloading imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "f6a094b70cdb49afbb526ce3a34c5cbf",
            "7ca2b47cf2d2402892c6acc4595eed05",
            "320c8fbc01404cea8a75e777956732a2",
            "80b7d90fea96455dabb1f21d7ac276be",
            "7d70be8d89c0428481ded96649c5e8da",
            "521c8466dc244d21bf20521d1ad94c00",
            "11f912bbadb9434aaa9b82cc068aa71d",
            "0263eabee41646b4b2c1882f215df7f6",
            "5f386c87fe6a4ed2bb24ee3fa781bf45",
            "2da3191505df4c169131f771e267d950",
            "c3ddc63cd36a4ab8be114a892f2d8840"
          ]
        },
        "id": "8Sg4aV0cmVPs",
        "outputId": "3fd54811-2a05-4429-d09d-6b62379a3d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-cc043f219420>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for th in tqdm(np.linspace(0., 360., 120, endpoint=False)):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/120 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6a094b70cdb49afbb526ce3a34c5cbf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "frames = []\n",
        "for th in tqdm(np.linspace(0., 360., 120, endpoint=False)):\n",
        "    c2w = pose_spherical(th, -30., 4.)\n",
        "    rays_o, rays_d = get_rays(H, W, focal, c2w[:3,:4])\n",
        "    rgb, depth, acc = render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
        "    frames.append((255*np.clip(rgb,0,1)).astype(np.uint8))\n",
        "\n",
        "import imageio\n",
        "f = 'video.mp4'\n",
        "imageio.mimsave('NeRF.gif', frames, fps=60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv-tf115",
      "language": "python",
      "name": "venv-tf115"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f6a094b70cdb49afbb526ce3a34c5cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ca2b47cf2d2402892c6acc4595eed05",
              "IPY_MODEL_320c8fbc01404cea8a75e777956732a2",
              "IPY_MODEL_80b7d90fea96455dabb1f21d7ac276be"
            ],
            "layout": "IPY_MODEL_7d70be8d89c0428481ded96649c5e8da"
          }
        },
        "7ca2b47cf2d2402892c6acc4595eed05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_521c8466dc244d21bf20521d1ad94c00",
            "placeholder": "​",
            "style": "IPY_MODEL_11f912bbadb9434aaa9b82cc068aa71d",
            "value": "100%"
          }
        },
        "320c8fbc01404cea8a75e777956732a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0263eabee41646b4b2c1882f215df7f6",
            "max": 120,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f386c87fe6a4ed2bb24ee3fa781bf45",
            "value": 120
          }
        },
        "80b7d90fea96455dabb1f21d7ac276be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2da3191505df4c169131f771e267d950",
            "placeholder": "​",
            "style": "IPY_MODEL_c3ddc63cd36a4ab8be114a892f2d8840",
            "value": " 120/120 [00:37&lt;00:00,  2.71it/s]"
          }
        },
        "7d70be8d89c0428481ded96649c5e8da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "521c8466dc244d21bf20521d1ad94c00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11f912bbadb9434aaa9b82cc068aa71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0263eabee41646b4b2c1882f215df7f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f386c87fe6a4ed2bb24ee3fa781bf45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2da3191505df4c169131f771e267d950": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3ddc63cd36a4ab8be114a892f2d8840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}